{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from reds_dataset import Reds\n",
    "from data.vimeo_dataset import VimeoDataset\n",
    "from models.superresblock import SuperRes\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from models.lossfunc import PerceptualLoss\n",
    "from train import train, test, setup_data\n",
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./\"\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training_data']\n"
     ]
    }
   ],
   "source": [
    "super_res_data = VimeoDataset(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SuperRes()\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-3) #parameters returns an iterator over the models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = vgg16(pretrained=True)\n",
    "relu2_2 = nn.Sequential(*list(vgg.features)[:9])\n",
    "relu2_2.eval()\n",
    "if use_cuda:\n",
    "    relu2_2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = PerceptualLoss(loss_network=relu2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gotta write code to visualise some of our data\n",
    "ftrain = \"./\"#file path to train\n",
    "ftest = \"./\"#file path to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training_data']\n",
      "['training_data']\n"
     ]
    }
   ],
   "source": [
    "trainloader_task_2, testloader_task_2 = setup_data(ftrain, ftest, 32,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1 #to see if we have no errors, we can set this value to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data/frame792.jpg\n",
      "training_data/frame340.jpg\n",
      "training_data/frame721.jpg\n",
      "training_data/frame674.jpg\n",
      "training_data/frame251.jpg\n",
      "training_data/frame885.jpg\n",
      "training_data/frame568.jpg\n",
      "training_data/frame923.jpg\n",
      "training_data/frame1060.jpg\n",
      "training_data/frame576.jpg\n",
      "training_data/frame72.jpg\n",
      "training_data/frame666.jpg\n",
      "training_data/frame759.jpg\n",
      "training_data/frame389.jpg\n",
      "training_data/frame682.jpg\n",
      "training_data/frame520.jpg\n",
      "training_data/frame786.jpg\n",
      "training_data/frame830.jpg\n",
      "training_data/frame294.jpg\n",
      "training_data/frame335.jpg\n",
      "training_data/frame1137.jpg\n",
      "training_data/frame1156.jpg\n",
      "training_data/frame938.jpg\n",
      "training_data/frame11.jpg\n",
      "training_data/frame1015.jpg\n",
      "training_data/frame1026.jpg\n",
      "training_data/frame290.jpg\n",
      "training_data/frame517.jpg\n",
      "training_data/frame774.jpg\n",
      "training_data/frame831.jpg\n",
      "training_data/frame859.jpg\n",
      "training_data/frame614.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tejvirjogani/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6088072061538696\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"Current Epoch: %d\" % epoch)\n",
    "    train(model, trainloader_task_2, optimizer, cuda_enabled=use_cuda)\n",
    "    test(model, testloader_task_2, cuda_enabled=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = model(prep_img(super_res_data[0][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
